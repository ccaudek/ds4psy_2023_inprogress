
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Intervallo fiduciale &#8212; ds4psy</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Significatività statistica" href="226_test_ipotesi.html" />
    <link rel="prev" title="Legge dei grandi numeri" href="220_intro_frequentist.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">ds4psy</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Nozioni di base
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Prefazione
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="001_key_notions.html">
   Concetti chiave
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_measurement.html">
   La misurazione in psicologia
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_freq_distr.html">
   Analisi esplorativa dei dati
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="011_loc_scale.html">
   Indici di posizione e di scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="012_correlation.html">
   Le relazioni tra variabili
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="013_eda_quickstart.html">
   Introduzione alla data analisi
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probabilità
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="014_dice.html">
   Calcolo combinatorio
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="015_intro_prob.html">
   La logica dell’incerto
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="016_conditional_prob.html">
   Probabilità condizionata: significato, teoremi, eventi indipendenti
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="017_bayes_theorem.html">
   Il teorema di Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="018_expval_var.html">
   Indici di posizione, di varianza e di associazione di variabili casuali
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="019_joint_prob.html">
   Probabilità congiunta
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="020_density_func.html">
   La densità di probabilità
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Distribuzioni di v.c.
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="022_discr_rv_distr.html">
   Distribuzioni di v.c. discrete
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="023_cont_rv_distr.html">
   Distribuzioni di v.c. continue
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="024_likelihood.html">
   La verosimiglianza
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Inferenza bayesiana
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="025_intro_bayes.html">
   Credibilità, modelli e parametri
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="026_subj_prop.html">
   Pensare ad una proporzione in termini soggettivi
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="029_conjugate_families.html">
   Distribuzioni coniugate
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_balance_prior_post.html">
   L’influenza della distribuzione a priori
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="036_metropolis.html">
   Approssimazione della distribuzione a posteriori
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="040_beta_binomial.html">
   Markov Chain Monte Carlo per l’inferenza bayesiana
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="050_normal_normal_mod.html">
   Inferenza su una media
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Regressione lineare
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="051_reglin_1.html">
   Introduzione
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="052_reglin_2.html">
   Regressione lineare bivariata
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="053_reglin_3.html">
   Regressione lineare con PyMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="054_reglin_4.html">
   Confronto tra le medie di due gruppi
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Inferenza frequentista
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="220_intro_frequentist.html">
   Legge dei grandi numeri
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Intervallo fiduciale
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="226_test_ipotesi.html">
   Significatività statistica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="228_limiti_stat_frequentista.html">
   Limiti dell’inferenza frequentista
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="230_s_m_errors.html">
   Errori di tipo
   <em>
    m
   </em>
   (magnitude) e di tipo
   <em>
    s
   </em>
   (sign)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bibliografia
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="z_biblio.html">
   Bibliografia
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendici
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="a01_math_symbols.html">
   Simbologia di base
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="a02_number_sets.html">
   Numeri binari, interi, razionali, irrazionali e reali
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="a04_summation_notation.html">
   Simbolo di somma (sommatorie)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="a05_calculus_notation.html">
   Per liberarvi dai terrori preliminari
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ccaudek/ds4psy_2023/master?urlpath=tree/docs/221_conf_interv.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ccaudek/ds4psy_2023"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ccaudek/ds4psy_2023/issues/new?title=Issue%20on%20page%20%2F221_conf_interv.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/221_conf_interv.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#la-variabilita-campionaria">
   La variabilità campionaria
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#l-errore-standard">
   L’errore standard
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#che-cos-e-l-intervallo-fiduciale">
   Che cos’è l’intervallo fiduciale?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#come-si-calcola-l-intervallo-fiduciale">
   Come si calcola l’intervallo fiduciale?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#il-livello-di-copertura">
   Il livello di copertura
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretazione">
   Interpretazione
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fraintendimenti">
     Fraintendimenti
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">
   Commenti e considerazioni finali
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Intervallo fiduciale</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#la-variabilita-campionaria">
   La variabilità campionaria
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#l-errore-standard">
   L’errore standard
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#che-cos-e-l-intervallo-fiduciale">
   Che cos’è l’intervallo fiduciale?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#come-si-calcola-l-intervallo-fiduciale">
   Come si calcola l’intervallo fiduciale?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#il-livello-di-copertura">
   Il livello di copertura
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretazione">
   Interpretazione
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fraintendimenti">
     Fraintendimenti
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">
   Commenti e considerazioni finali
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="intervallo-fiduciale">
<span id="sec-interv-conf"></span><h1>Intervallo fiduciale<a class="headerlink" href="#intervallo-fiduciale" title="Permalink to this headline">#</a></h1>
<section id="la-variabilita-campionaria">
<h2>La variabilità campionaria<a class="headerlink" href="#la-variabilita-campionaria" title="Permalink to this headline">#</a></h2>
<p>Consideriamo, quale esempio, l’esperimento casuale che corrisponde all’estrazione casuale di un campione di <span class="math notranslate nohighlight">\(n\)</span> osservazioni da una popolazione e del calcolo della media di quel campione. Dato che si immagina che l’esperimento casuale venga ripetuto infinite volte, dobbiamo immaginare l’esistenza di infiniti campioni casuali di <span class="math notranslate nohighlight">\(n\)</span> osservazioni. Dato che ciascuno di tali campioni è costituito da osservazioni diverse, ognuno di essi avrà una media diversa. Tale fenomeno è detto <em>variabilità campionaria</em>. Se usiamo il linguaggio dell’approccio frequentista diremo che la distribuzione dei tutti gli infiniti possibili valori della statistica in questione (nel caso dell’esempio, la media del campione) nell’universo dei campioni si chiama <em>distribuzione campionaria</em>.</p>
<p>Se lo psicologo usa la media del campione quale stima della media della popolazione, ovviamente commetterà un errore, dato che la statistica campionaria è sempre diversa dal parametro. Il problema dello psicologo è quello di valutare l’entità di tale errore, ovvero quello di valutare il livello di incertezza inerente alla sua stima.</p>
<p>Per valutare l’incertezza della stima lo psicologo fa riferimento alla variabilità campionaria. Se la deviazione standard della distribuzione campionaria della statistica è piccola, questo significa che ogni campione casuale di ampiezza <span class="math notranslate nohighlight">\(n\)</span> produrrà una statistica <span class="math notranslate nohighlight">\(\bar{X}\)</span> simile al parametro <span class="math notranslate nohighlight">\(\mu\)</span> della popolazione. In tali condizioni (utilizzando i dati di un singolo campione) ci sarà una piccola incertezza relativamente al valore del parametro, perché, in media, <span class="math notranslate nohighlight">\(\bar{X}\)</span> è simile a <span class="math notranslate nohighlight">\(\mu\)</span>. Se invece la deviazione standard della distribuzione campionaria di <span class="math notranslate nohighlight">\(\bar{X}\)</span> è grande, i campioni casuali di ampiezza <span class="math notranslate nohighlight">\(n\)</span> produrranno, in media, una statistica <span class="math notranslate nohighlight">\(\bar{X}\)</span> molto lontana dal parametro <span class="math notranslate nohighlight">\(\mu\)</span>. Utilizzando i dati di un singolo campione, in tali condizioni lo psicologo sarà molto incerto relativamente al vero valore del parametro (in quanto, in media, <span class="math notranslate nohighlight">\(\bar{X}\)</span> è molto diverso da <span class="math notranslate nohighlight">\(\mu\)</span>).</p>
<p>La deviazione standard della distribuzione campionaria, detta <em>errore standard</em>, viene dunque utilizzata per quantificare l’incertezza relativamente alla stima di un parametro. Solitamente, l’approccio frequentista quantifica l’incertezza della stima nei termini di una funzione dell’errore standard chiamata <em>intervallo fiduciale</em>. Lo scopo di questo capitolo è quello di introdurre la nozione di errore standard in modo tale da potere fornire un’interpretazione alla nozione di intervallo fiduciale.</p>
</section>
<section id="l-errore-standard">
<h2>L’errore standard<a class="headerlink" href="#l-errore-standard" title="Permalink to this headline">#</a></h2>
<p>Per fare un esempio, chiediamoci come sia possibile misurare la variabilità della proporzione di studenti promossi, se prendiamo in considerazione tutti i possibili appelli d’esame di Psicometria a Firenze (quelli passati, quelli presenti e anche quelli futuri). Da ciò che è stato presentato in precedenza, sappiamo che la statistica più utile per quantificare la variabilità di una variabile è la deviazione standard. Questo fatto fornisce la risposta anche alla domanda che ci siamo posti ora: in linea di principio, potremmo usare la deviazione standard per descrivere di quanto variano, in media, i valori delle proporzioni di studenti promossi in tutti i possibili appelli d’esame di Psicometria a Firenze. Un problema che dobbiamo affrontare, però, riguarda il fatto che la distribuzione di valori a cui facciamo riferimento è una distribuzione di valori virtuali, non è un insieme di dati che abbiamo osservato. Per calcolare la deviazione standard, dunque, dobbiamo procedere in modo diverso da quanto abbiamo fatto in precedenza. Iniziamo con un po’ di terminologia.</p>
<div class="admonition-definizione admonition">
<p class="admonition-title">Definizione</p>
<p>Si dice <em>errore standard</em> la deviazione standard dei valori una statistica campionaria nell’universo dei campioni.</p>
</div>
<p>L’errore standard è molto importante perché descrive l’accuratezza della nostra stima. Se l’errore standard è piccolo questo ci dice che, se osserviamo un campione diverso da quello corrente, allora ci aspettiamo che la statistica in esame abbia un valore simile a quello corrente. Un grande errore standard, invece, ci dice che non dobbiamo assegnare troppa fiducia alla stima ottenuta nel campione a disposizione perché, in un altro campione, si otterrà una stima molto diversa, e, in media, i valori ottenuti in campioni diversi saranno lontani dal vero valore del parametro sconosciuto (ovvero, nell’esempio considerato, dalla media di tutte le proporzioni che si possono ottenere).</p>
<p>Il calcolo dell’errore standard è solitamente lasciato ad un software. Ma come si arriva ad una quantificazione dell’errore standard? Forniamo qui solo una descrizione intuitiva della procedura che viene seguita e forniamo la seguente definizione.</p>
<div class="admonition-definizione admonition">
<p class="admonition-title">Definizione</p>
<p>L’errore standard può essere inteso come una misura (del reciproco) della curvatura della verosimiglianza in corrispondenza della stima di massima verosimiglianza per un parametro <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
<p>Per capire come si traduce in pratica questa definizione, esaminiamo la figura seguente. Nel pannello di sinistra è riprodotta la funzione di verosimiglianza nel caso di 7 successi in 10 prove Bernoulliane. Nel pannello centrale è riportata la verosimiglianza per 70 successi in 100 prove e nel pannello di destra abbiamo la verosimiglianza nel caso di 700 successi in 1000 prove.</p>
<p><img alt="" src="_images/likelihood_and_SE.png" /></p>
<p>Sinistra: funzione di verosimiglianza nel caso di 7 successi in 10 prove Bernoulliane; centro: funzione di verosimiglianza nel caso di 70 successi in 100 prove; destra: funzione di verosimiglianza nel caso di 700 successi in 1000 prove.</p>
<p>Quello che la figura ci dice è che, al crescere del numero di prove, diminuisce la nostra incertezza relativamente al valore del parametro <span class="math notranslate nohighlight">\(\pi\)</span> (probabilità di successo, ovvero, la media di tutte le proporzioni campionarie). Nel caso di un piccolo numero di prove, la verosimiglianza ha una piccola curvatura e ci fornisce una modesta quantità di informazione concernente il parametro non osservabile <span class="math notranslate nohighlight">\(\pi\)</span> – in altri termini, la verosimiglianza definisce un intervallo piuttosto ampio di valori <span class="math notranslate nohighlight">\(\pi\)</span> la cui plausibilità relativa è piuttosto grande. Con un grande numero di prove, invece, la verosimiglianza ha un picco molto più marcato che associa livelli relativamente alti di plausibilità ad un intervallo molto più piccolo di valori <span class="math notranslate nohighlight">\(\pi\)</span>. In altre parole, maggiore è la curvatura della verosimiglianza, maggiore è la quantità di informazione che il campione fornisce rispetto al valore del parametro sconosciuto che vogliamo stimare.</p>
<p>In termini formali, la curvatura è la derivata seconda di una funzione e, appunto, calcolando la derivata seconda della funzione di verosimiglianza possiamo trovare l’errore standard di una statistica. Nel caso presente, l’errore standard della proporzione campionaria è</p>
<div class="math notranslate nohighlight">
\[
\sigma_{\hat{\pi}} = \sqrt{\frac{p (1-p)}{n}},
\]</div>
<p>dove <span class="math notranslate nohighlight">\(p\)</span> è la proporzione campionaria e <span class="math notranslate nohighlight">\(n\)</span> è il numero di osservazioni. Questa quantità si interpreta come qualunque deviazione standard: nello specifico, ci dice quanto varia in media la proporzione campionari se consideriamo campioni diversi. Si noti che, avendo <span class="math notranslate nohighlight">\(n\)</span> al denominatore, la formula riproduce l’intuizione che abbiamo descritto mediante la &#64;fig-like-se: quando <span class="math notranslate nohighlight">\(n\)</span> è grande l’errore standard è piccolo e, viceversa, quando <span class="math notranslate nohighlight">\(n\)</span> è piccolo l’errore standard è grande. In altri termini, quando l’errore standard di una stima è piccolo, possiamo attribuire un grande livello di fiducia al valore della stima del parametro. Invece, un grande errore standard ci suggerisce ad essere cauti in qualunque inferenza che potremmo trarre dalla stima che abbiamo ottenuto.</p>
</section>
<section id="che-cos-e-l-intervallo-fiduciale">
<h2>Che cos’è l’intervallo fiduciale?<a class="headerlink" href="#che-cos-e-l-intervallo-fiduciale" title="Permalink to this headline">#</a></h2>
<p>L’approccio frequentista non si limita al calcolo dell’errore standard ma affronta il problema di quantificare il grado di incertezza associato alle stime campionarie utilizzando un altro concetto, ovvero la nozione di <em>intervallo di fiducia</em>. Vale la pena di sottolineare che il principale significato del termine inglese <em>confidence</em> non è <em>confidenza</em> bensì <em>fiducia</em>. L’intervallo di fiducia è una semplice trasformazione dell’errore standard e tale nozione può essere chiarita nel modo seguente.</p>
<p>La stima <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> di un parametro <span class="math notranslate nohighlight">\(\theta\)</span> si determina esaminando i dati forniti da un campione casuale. Sappiamo che il valore empirico <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> non coincide mai con il vero valore del parametro (dato che il campione è diverso dalla popolazione). Conoscendo la distribuzione di <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> diventa però possibile valutare l’errore commesso e definire l’intervallo <span class="math notranslate nohighlight">\([\theta_{min} \leq \hat{\theta} \leq \theta_{max}]\)</span> che, <em>a lungo termine</em>, comprende il valore del parametro incognito <span class="math notranslate nohighlight">\(\theta\)</span> con una probabilità <span class="math notranslate nohighlight">\(\gamma \in [0, 1]\)</span> prossima ad 1. Questo intervallo si chiama intervallo fiduciale.</p>
<div class="admonition-definizione admonition">
<p class="admonition-title">Definizione</p>
<p>Si dice intervallo fiduciale l’intervallo <span class="math notranslate nohighlight">\([\theta_{min}, \theta_{max}]\)</span> tale che</p>
<div class="math notranslate nohighlight">
\[
P(\theta_{min} \leq \theta \leq \theta_{max}) \geq \gamma, \qquad \forall \theta \in \Theta,
\]</div>
<p>dove <span class="math notranslate nohighlight">\(\Theta\)</span> indica l’insieme dei valori possibili del parametro <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
<p>Gli estremi dell’intervallo di fiducia sono chiamati limiti fiduciari e la probabilità <span class="math notranslate nohighlight">\(\gamma\)</span> è chiamata livello fiduciario; espressa in percentuale, essa esprime il livello di significatività della stima effettuata.</p>
</section>
<section id="come-si-calcola-l-intervallo-fiduciale">
<h2>Come si calcola l’intervallo fiduciale?<a class="headerlink" href="#come-si-calcola-l-intervallo-fiduciale" title="Permalink to this headline">#</a></h2>
<p>In alcuni casi, la distribuzione delle statistiche campionarie approssima la Normale e, in tali casi, l’intervallo fiduciale al 95% è dato da</p>
<div class="math notranslate nohighlight">
\[
\hat{\theta} \pm 1.96 \cdot \text{SE}, \notag
\]</div>
<p>ovvero, dalla stima del parametro <span class="math notranslate nohighlight">\(\pm\)</span> 1.96 volte l’errore standard.</p>
<p>Conoscendo l’errore standard, è dunque molto semplice calcolare l’intervallo fiduciale. Meno semplice, invece, è interpretare l’intervallo fiduciale nel modo corretto. Per capire quale sia l’interpretazione corretta dell’intervallo fiduciale, iniziamo a definire il concetto di livello di copertura.</p>
</section>
<section id="il-livello-di-copertura">
<h2>Il livello di copertura<a class="headerlink" href="#il-livello-di-copertura" title="Permalink to this headline">#</a></h2>
<p>Si indica con <span class="math notranslate nohighlight">\(1-\alpha\)</span> il <em>livello di copertura</em> fornito dall’intervallo fiduciale. Il termine probabilità di copertura si riferisce alla probabilità che la procedura per la costruzione degli intervalli di fiducia produca un intervallo che contiene (o copre) il valore reale del parametro di interesse. Esiste infatti sempre una probabilità pari ad <span class="math notranslate nohighlight">\(\alpha\)</span> che i dati campionari producano un intervallo che non contiene il valore reale del parametro di interesse.</p>
<p>Ricordiamo che l’approccio frequentista interpreta la probabilità di un evento come la proporzione di volte in cui tale evento si verifica avendo osservato molte ripetizioni indipendenti di un esperimento casuale. Nel caso presente, l’evento in questione è la risposta alla domanda “l’intervallo fiduciale contiene il valore del parametro?” mentre l’esperimento casuale corrisponde al calcolo dell’intervallo fiduciale per la statistica in question in un campione casuale di ampiezza <span class="math notranslate nohighlight">\(n\)</span>. L’interpretazione frequentista della nozione di livello di copertura può essere chiarita mediante la seguente simulazione.</p>
<p>Prendiamo in considerazione la distribuzione dell’altezza degli adulti maschi nella popolazione. Sappiamo che l’altezza degli individui segue la distribuzione normale. Sappiamo inoltre che, per esempio, l’altezza media di un italiano adulto maschio è di <span class="math notranslate nohighlight">\(175\)</span> cm, con una varianza di <span class="math notranslate nohighlight">\(49\)</span> cm<span class="math notranslate nohighlight">\(^2\)</span>. Utilizziamo queste informazioni per realizzare la seguente simulazione in R. Nella simulazione prevediamo 100 ripetizioni dell’esperimento casuale che consiste nell’estrazione di un campione di ampiezza <span class="math notranslate nohighlight">\(n = 20\)</span> dalla popolazione distribuita come <span class="math notranslate nohighlight">\(\mathcal{N}(175, 7)\)</span>. Per ciascun campione casuale così trovato utilizzeremo poi la funzione <code class="docutils literal notranslate"><span class="pre">t.test()</span></code> per calcolare l’intervallo fiduciale al 95%. Salveremo quindi nella matrice <code class="docutils literal notranslate"><span class="pre">sampling_distribution</span></code> il limite inferiore e il limite superiore dell’intervallo fiduciale trovato in ciascuno dei 100 campioni.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">CI_coverage</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; creates n_samples samples of size n</span>
<span class="sd">        creates an 1-alpha confidence interval for each</span>
<span class="sd">        computes the fraction of those that contain mu &#39;&#39;&#39;</span>
    <span class="c1"># get samples</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
    <span class="c1"># summary stats</span>
    <span class="n">xbar</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compute CIs... note that xbar, s, CI_low, CI_high are arrays size n_samples</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">interval_width</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">samples</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">CI_low</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">interval_width</span>
    <span class="n">CI_high</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">interval_width</span>
    <span class="c1"># coverage</span>
    <span class="n">coverage_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">CI_low</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">,</span> <span class="n">mu</span> <span class="o">&lt;</span> <span class="n">CI_high</span><span class="p">))</span> <span class="o">/</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">coverage_p</span>
</pre></div>
</div>
</div>
</div>
<p>Otteniamo 1000 campioni casuali di ampiezza <span class="math notranslate nohighlight">\(n\)</span> = 30 da una <span class="math notranslate nohighlight">\(\mathcal{N}(175, 7)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mi">175</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
<span class="n">samples</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000, 30)
</pre></div>
</div>
</div>
</div>
<p>Il primo campione è il seguente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>158.85280419860126 165.31647637154424 167.6343506872001 164.54006313356558 180.5097345277032 176.7316118383534 170.43566171483332 181.92837345027473 187.28949414956136 172.60828761927573 175.010919055638 168.6058130859855 187.62681634981095 174.5114325195618 164.0551200208089 174.8876280585434 166.84686537158444 174.1259853475981 182.1237159404306 171.574874855374 176.1404754548807 187.99770703458276 169.44637778424502 185.70851030254275 172.34915615641572 175.62694644090524 168.7872456708928 181.9717241641825 173.24107735633046 175.863437590279
</pre></div>
</div>
</div>
</div>
<p>Queste sono le medie dei primi dieci campioni di ampiezza <span class="math notranslate nohighlight">\(n\)</span> = 30.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xbar</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">xbar</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>177.04363208353348 174.41162287505023 177.075766980725 175.40605969556836 172.86300133369247 174.8091611786862 171.58848073721578 171.04849000877505 175.13452480119517 172.8137520760075
</pre></div>
</div>
</div>
</div>
<p>Troviamo il valore critico della distribuzione <span class="math notranslate nohighlight">\(t\)</span> di Student con (30-1) gradi di libertà.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.045229642132703
</pre></div>
</div>
</div>
</div>
<p>Calcoliamo i 1000 intervalli di fiducia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interval_width</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">samples</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">CI_low</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">interval_width</span>
<span class="n">CI_high</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">interval_width</span>
</pre></div>
</div>
</div>
</div>
<p>Troviamo il livello di copertura</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coverage_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">CI_low</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">,</span> <span class="n">mu</span> <span class="o">&lt;</span> <span class="n">CI_high</span><span class="p">))</span> <span class="o">/</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">coverage_p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.946
</pre></div>
</div>
</div>
</div>
<p>In conclusione, ripetendo la simulazione 1000 volte troviamo un livello di copertura (ovvero, una proporzione di intervalli fiduciali del 95% che contengono il parametro) molto prossimo al livello nominale <span class="math notranslate nohighlight">\(1 - \alpha = 0.95\)</span>.</p>
</section>
<section id="interpretazione">
<h2>Interpretazione<a class="headerlink" href="#interpretazione" title="Permalink to this headline">#</a></h2>
<p>Studenti e ricercatori tendono ad interpretare gli intervalli fiduciali dicendo che “c’è una probabilità del 95% che la vera media della popolazione si trovi all’interno dell’intervallo fiduciale”. Questa è un’interpretazione semplice e cattura l’idea del senso comune secondo la quale una probabilità di 0.95 significa: “sono sicuro al 95%”. Sfortunatamente, l’interpretazione precedente è sbagliata. La precedente interpretazione richiede che la probabilità venga descritta in termini soggettivi e corrisponde a dire: “sono fiducioso al 95% che l’intervallo così costruito contenga la media della popolazione, perché questa è la mia opinione”. Nella vita di tutti i giorni un tale punto di vista va benissimo, ma parlare di opinioni soggettive e di fiducia è un’idea Bayesiana. Non c’è niente di male con l’idea che la nozione “probabilità del 95%” possa riferirsi a un’opinione personale. Tuttavia, gli intervalli fiduciali sono una procedura statistica di stampo frequentista, non Bayesiano. Se usiamo degli strumenti statistici frequentisti per costruire l’intervallo fiduciale non possiamo attribuire ad esso un’interpretazione Bayesiana, ma dobbiamo interpretare tale intervallo di valori in maniera coerente con l’impianto teorico frequentista – anche perché gli intervalli di fiducia frequentisti e gli intervalli di credibilità Bayesiani sono numericamente diversi!</p>
<p>Se l’interpretazione presentata sopra non è corretta, allora qual è l’interpretazione corretta dell’intervallo fiduciale? Dobbiamo ricordare ciò che abbiamo detto sulla probabilità frequentista: in base all’approccio frequentista la probabilità di un evento è alla proporzione di volte con la quale un evento si è verificato in una sequenza di esperimenti casuali. È necessario ripetere tante volte un esperimento casuale, anche solo in maniera ipotetica (come nella simulazione descritta sopra), altrimenti non è possibile parlare di probabilità. L’interpretazione frequentista di un intervallo fiduciale deve avere a che fare con la ripetizione di un esperimento casuale e può essere formulata nel modo seguente.</p>
<div class="admonition-definizione admonition">
<p class="admonition-title">Definizione</p>
<p>Se ripetessimo tante volte l’esperimento casuale che consiste nell’estrarre un campione casuale dalla popolazione e nel calcolare l’intervallo fiduciale al 95%, allora nel 95% dei casi gli intervalli così calcolati conterrebbero il vero valore del parametro.</p>
</div>
<p>Più in generale, se si estraggono successivamente più campioni indipendenti dalla stessa popolazione e se si determinano i relativi intervalli fiduciali seguendo la procedura indicata dalla statistica frequentista, allora il <span class="math notranslate nohighlight">\(100 (1-\alpha)\)</span>% degli intervalli così calcolati conterrà il vero valore del parametro incognito.</p>
<p>Questa è l’interpretazione corretta che deve essere attribuita alla nozione di intervallo fiduciale al livello <span class="math notranslate nohighlight">\(100 (1-\alpha)\)</span>%. È però risaputo come i ricercatori (non solo gli studenti!) spesso attribuiscono agli intervalli fiduciali un’interpretazione errata, come abbiamo descritto sopra. Non poche volte nelle riviste specialistiche si leggono affermazioni del tipo: “la probabilità che la media della popolazione <span class="math notranslate nohighlight">\(\mu\)</span> sia contenuta nell’intervallo <span class="math notranslate nohighlight">\([\hat{a}, \hat{b}]\)</span> è 0.95”, mentre in realtà si dovrebbe scrivere: “la procedura tramite la quale l’intervallo <span class="math notranslate nohighlight">\([\hat{a}, \hat{b}]\)</span> è stato calcolato include <span class="math notranslate nohighlight">\(\mu\)</span> nel 95% dei casi”.</p>
<section id="fraintendimenti">
<h3>Fraintendimenti<a class="headerlink" href="#fraintendimenti" title="Permalink to this headline">#</a></h3>
<p><span id="id1">[<a class="reference internal" href="z_biblio.html#id12" title="Rink Hoekstra, Richard D Morey, Jeffrey N Rouder, and Eric-Jan Wagenmakers. Robust misinterpretation of confidence intervals. Psychonomic Bulletin &amp; Review, 21(5):1157–1164, 2014.">HMRW14</a>]</span> notano che, essendo ampiamente riconosciuti i limiti del test dell’ipotesi nulla, per l’inferenza statistica viene spesso consigliato l’utilizzo degli intervalli di fiducia. Per esempio, l’<em>American Psychological Association Publication Manual</em> fa riferimento agli intervalli di fiducia affermando che essi rappresentano <em>in general, the best reporting strategy</em> (APA, 2001, p. 22; APA, 2009, p. 34). <span id="id2">[<a class="reference internal" href="z_biblio.html#id12" title="Rink Hoekstra, Richard D Morey, Jeffrey N Rouder, and Eric-Jan Wagenmakers. Robust misinterpretation of confidence intervals. Psychonomic Bulletin &amp; Review, 21(5):1157–1164, 2014.">HMRW14</a>]</span> fanno notare, però, che tali raccomdandazioni hanno dei limiti, in quanto non tengono in considerazione la difficoltà che hanno i ricercatori a fornire agli intervalli di fiducia l’interpretazione corretta. A sostegno di questo punto di vista, <span id="id3">[<a class="reference internal" href="z_biblio.html#id12" title="Rink Hoekstra, Richard D Morey, Jeffrey N Rouder, and Eric-Jan Wagenmakers. Robust misinterpretation of confidence intervals. Psychonomic Bulletin &amp; Review, 21(5):1157–1164, 2014.">HMRW14</a>]</span> hanno svolto uno studio nel quale si sono posti due domande:</p>
<ul class="simple">
<li><p>in che misura gli intervalli di fiducia vengono interpretati in maniera sbagliata da studenti e ricercatori?</p></li>
<li><p>le interpretazioni errate degli intervalli di fiducia diminuiscono con l’esperienza nell’ambito della ricerca?</p></li>
</ul>
<p>Prima di presentare lo studio, <span id="id4">[<a class="reference internal" href="z_biblio.html#id12" title="Rink Hoekstra, Richard D Morey, Jeffrey N Rouder, and Eric-Jan Wagenmakers. Robust misinterpretation of confidence intervals. Psychonomic Bulletin &amp; Review, 21(5):1157–1164, 2014.">HMRW14</a>]</span> ricordano quale sia l’interpretazione corretta degli intervalli di fiducia. Il lettore può mettere in relazione la seguente citazione con ciò che è stato discusso in precedenza.</p>
<blockquote>
<div><p>A CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (\emph{e.g.}, Berger &amp; Wolpert, 1988). As is the case with <span class="math notranslate nohighlight">\(p\)</span>-values, CIs do not allow one to make probability statements about parameters or hypotheses.</p>
</div></blockquote>
<p>Nello studio, <span id="id5">[<a class="reference internal" href="z_biblio.html#id12" title="Rink Hoekstra, Richard D Morey, Jeffrey N Rouder, and Eric-Jan Wagenmakers. Robust misinterpretation of confidence intervals. Psychonomic Bulletin &amp; Review, 21(5):1157–1164, 2014.">HMRW14</a>]</span> hanno sottoposto il questionario riportato di seguito ad un campione di 596 partecipanti. Il campione includeva 442 studenti di psicologia del primo anno che seguivano un corso introduttivo di statistica presso l’università di Amsterdam, 34 studenti di master e 120 ricercatori (cioè dottorandi e docenti universitari).</p>
<blockquote>
<div><p>Professor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.</p>
</div></blockquote>
<blockquote>
<div><ol class="simple">
<li><p>The probability that the true mean is greater than 0 is at least 95%.</p></li>
<li><p>The probability that the true mean equals 0 is smaller than 5%.</p></li>
<li><p>The “null hypothesis” that the true mean equals 0 is likely to be incorrect.</p></li>
<li><p>There is a 95% probability that the true mean lies between 0.1 and 0.4.</p></li>
<li><p>We can be 95% confident that the true mean lies between 0.1 and 0.4.</p></li>
<li><p>If we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.</p></li>
</ol>
</div></blockquote>
<p>Le sei affermazioni precedenti sono tutte errate. I risultati dello studio di &#64;hoekstra2014robust mostrano però che i partecipanti si sono dichiarati d’accordo con il seguente numero medio di item (su 6): 3.51 (99% CI = [3.35, 3.68]) per gli studenti del primo anno, 3.24 (99% CI = [2.40, 4.07]) per gli studenti di master e 3.45 (99% CI = [3.08, 3.82]) per i ricercatori. Gli intervalli di fiducia al 95% si sovrappongono per le tre categorie di rispondenti il che significa che, a tale livello di fiducia, non c’è ragione di ritenere che vi siano delle differenze tra i tre gruppi di rispondenti. In altre parole, questi dati suggeriscono che i ricercatori tendono a condividere con gli studenti di psicologia del primo anno le stesse opinioni (errate!) relativamente agli intervallo fiduciali.</p>
<p>Le interpretazioni errate degli intervalli di fiducia sono dunque molto diffuse e l’esperienza pratica nel mondo della ricerca non contribuisce ad una comprensione migliore di tale concetto. In generale, i risultati della ricerca di <span id="id6">[<a class="reference internal" href="z_biblio.html#id12" title="Rink Hoekstra, Richard D Morey, Jeffrey N Rouder, and Eric-Jan Wagenmakers. Robust misinterpretation of confidence intervals. Psychonomic Bulletin &amp; Review, 21(5):1157–1164, 2014.">HMRW14</a>]</span>, e di altre che hanno prodotto risultati simili, mettono in discussione l’utilità degli intervalli fiduciali frequentisti (dato che molto poche persone hanno una comprensione adeguata di tale concetto), favorendo invece l’uso degli “intervallo di credibilità” Bayesiani ai quali è più facile fornire un’interpretazione corretta, perché tale interpretazione coincide con le nostre intuizioni.</p>
</section>
</section>
<section id="commenti-e-considerazioni-finali">
<h2>Commenti e considerazioni finali<a class="headerlink" href="#commenti-e-considerazioni-finali" title="Permalink to this headline">#</a></h2>
<p>Gli intervalli fiduciali vengono spesso fraintesi. Il grado di fiducia del 95% riguarda la certezza che <em>nel lungo periodo</em> il 95% degli intervalli fiduciali includerà il parametro sconosciuto: nulla si può dire di uno specifico intervallo fiduciale, il quale può includere o non includere il parametro, ma il ricercatore non può saperlo. Inoltre, si può dire che non esiste alcuna relazione tra la varianza di un campione e la sua media. Pertanto non possiamo dedurre che un intervallo di fiducia più stretto sia anche più preciso. In un contesto frequentista, la precisione fa solo riferimento al livello di copertura nel lungo termine che viene fornita dalla procedura di generazione degli intervalli di fiducia: non riguarda il singolo intervallo che è stato osservato. Infatti, un intervallo di fiducia può essere molto stretto ma anche molto lontano dal vero valore del parametro sconosciuto.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="220_intro_frequentist.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Legge dei grandi numeri</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="226_test_ipotesi.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Significatività statistica</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Corrado Caudek<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>